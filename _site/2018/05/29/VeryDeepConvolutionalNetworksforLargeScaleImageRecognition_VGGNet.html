<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <!-- Main JS (navbar.js, katex_init.js and masonry_init.js)-->
    <script defer=true src="/assets/js/main.min.js"></script>
    
    <!-- CSS -->
    <link rel="stylesheet" href="/assets/css/main.css">

    <!--Favicon-->
    <link rel="shortcut icon" href="/assets/favicon.ico" type="image/x-icon">

    <!-- Canonical -->
    <link rel="canonical" href="https://damacho.github.io/2018/05/29/VeryDeepConvolutionalNetworksforLargeScaleImageRecognition_VGGNet.html">

    <!-- RSS -->
    <link rel="alternate" type="application/atom+xml" title="DaMacho" href="https://damacho.github.io/feed.xml"/>

    <!-- Font Awesome -->
    <!-- <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet"> -->
    <link rel="stylesheet" type="text/css" href="/assets/css/vendor/font-awesome.min.css">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/earlyaccess/nanumgothic.css">

    <!-- Google Fonts -->
    
    <link href="//fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,700italic,400italic" rel="stylesheet" type="text/css"> 

    

    <!-- KaTeX 0.8.3 -->
    
    <link rel="stylesheet" type="text/css" href="/assets/css/vendor/katex.min.css">
    <script src="/assets/js/vendor/katex.min.js">
    </script>
    

    <!-- Google Analytics -->
    
    <script>
        (function(i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r;
            i[r] = i[r] || function() {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o),
                m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m)
        })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-120963948-1', 'auto');
        ga('send', 'pageview');

    </script>
    
    
    <!-- seo tags -->
    
    <!-- Manual seo tags -->
    <!-- <title>VGGNet, "Very Deep Convolutional Networks for Large-Scale Image Recognition" (2014) | DaMacho</title> -->
    <meta name="generator" content="Jekyll v3.8.1" />
    <meta property="og:title" content="VGGNet, "Very Deep Convolutional Networks for Large-Scale Image Recognition" (2014)" />
    <meta property="og:locale" content="en_US" />
    <meta name="description" content="Review: VGGNet은 구조가 간단하며 이해나 변형이 쉬운 장점을 가진다. 하지만 FC로 인해 파라미터의 수가 매우 많다는 단점을 가지며, 이로 인해 필요한 메모리 수가 크고, 학습 시간이 오래 걸린다는 약점을 가진다." />
    <meta property="og:description" content="Review: VGGNet은 구조가 간단하며 이해나 변형이 쉬운 장점을 가진다. 하지만 FC로 인해 파라미터의 수가 매우 많다는 단점을 가지며, 이로 인해 필요한 메모리 수가 크고, 학습 시간이 오래 걸린다는 약점을 가진다." />
    <link rel="canonical" href="https://damacho.github.io/2018/05/29/VeryDeepConvolutionalNetworksforLargeScaleImageRecognition_VGGNet.html" />
    <meta property="og:url" content="https://damacho.github.io/2018/05/29/VeryDeepConvolutionalNetworksforLargeScaleImageRecognition_VGGNet.html" />
    <meta property="og:site_name" content="DaMacho" />
    <meta property="og:type" content="blog" />
    <script type="application/ld+json"></script>
    
    <title>VGGNet, "Very Deep Convolutional Networks for Large-Scale Image Recognition" (2014) | DaMacho</title>
    <meta name="description" content="Review: VGGNet은 구조가 간단하며 이해나 변형이 쉬운 장점을 가진다. 하지만 FC로 인해 파라미터의 수가 매우 많다는 단점을 가지며, 이로 인해 필요한 메모리 수가 크고, 학습 시간이 오래 걸린다는 약점을 가진다.">
   
</head>

  <body>
    <header class="site-header">
    
    <!-- Logo and title -->
	<div class="branding">
		<a href="/">
			<img class="avatar" src="/assets/img/salt.svg" alt=""/>
		</a>

		<h1 class="site-title">
			<a href="/">DaMacho</a>
		</h1>
	</div>
    
    <!-- Toggle menu -->
    <nav class="clear">
    <a id="pull" class="toggle" href="#">
    <i class="fa fa-bars fa-lg"></i>
    </a>
    
    <!-- Menu -->
    <ul class="hide">
        <!-- Auto Generation of NORMAL pages in the navbar -->
        
        
        
        
        
        
        
        <li class="separator"> | </li>
        <li>
            <a class="clear" href="/about/">
                About
            </a>
        </li>
        
        
        
        
        
        
        
        
        <li class="separator"> | </li>
        <li>
            <a class="clear" href="/gallery/">
                Gallery
            </a>
        </li>
        
        
        
        
        
        
        
        
        
        
        <li class="separator"> | </li>
        <li>
            <a class="clear" href="/portfolio/">
                Portfolio
            </a>
        </li>
        
        
        
        
        
        
        
        
        
        
        
        
        
         
        
        <!-- Auto Generation of SPECIAL pages in the navbar -->
        
          
            <li class="separator"> | </li>
            <li>
                <a class="clear" href="/search">
                    <i class="fa fa-search" aria-hidden="true"></i>
                </a>
            </li>
          
        
          
            <li class="separator"> | </li>
            <li>
                <a class="clear" href="/tags">
                    <i class="fa fa-tags" aria-hidden="true"></i>
                </a>
            </li>
          
        
    </ul>
        
	</nav>
</header>

    <div class="content">
      <!-- MathJax -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  
<!-- Read event -->
<script>
try {
  document.addEventListener("DOMContentLoaded", function() {
    var accumScrollMove = 0;
    // Set it 1 msecs to avoid div by zero error
    var accumScrollTime = 1;
    var latestScrollTop = 0;
    var latestScrollAt = new Date();
    
    function checkScroll() {
      // 1. Check scrollbar movement speed
      var scrollTop = document.body.scrollTop;
      var scrollAt = new Date();
      var scrollTopDelta = Math.abs(latestScrollTop - scrollTop);
      var scrollTimeDelta = Math.min(scrollAt - latestScrollAt, 5 * 60 * 1000); // limit max time-delta to 5 minutes
      if(scrollTopDelta !== 0) {
        latestScrollTop = scrollTop;
        latestScrollAt = scrollAt;
        accumScrollMove += scrollTopDelta;
        accumScrollTime += scrollTimeDelta;
      }
    
      // 2. Check event firing condition
       if(accumScrollTime > 30 * 1000 && scrollTop / document.body.scrollHeight > 0.8) {
        var pixelPerSec = Math.floor(accumScrollMove / accumScrollTime * 1000);
        var label = pixelPerSec > 100 ? 'skimmer' : 'reader';
        ga('send', 'event', 'read', 'pps', label, pixelPerSec);
      } else {
        window.setTimeout(checkScroll, 500);
      }
    }
    
   checkScroll();
  });
} catch(e) {}
</script>

<!-- IPython Notebook -->
<script>
document.addEventListener("DOMContentLoaded", function(e) {
  var cells = document.querySelectorAll('article .cell');
  for(var i = 0; i < cells.length; i++) {
    var cell = cells[i];
    cell.addEventListener('click', function() {
      var curClasses = this.getAttribute('class');
      if(curClasses.indexOf(' expanded') !== -1) {
        this.setAttribute('class', curClasses.substring(0, curClasses.length - 9));
      } else {
        this.setAttribute('class', curClasses + ' expanded');
      }
    });
  }
});
</script>

<article >
  <header id="main" style="background-image: url('/')">
    <h1 id="VGGNet%2C+%22Very+Deep+Convolutional+Networks+for+Large-Scale+Image+Recognition%22+%282014%29" class="title">VGGNet, "Very Deep Convolutional Networks for Large-Scale Image Recognition" (2014)</h1>
    <p class="meta">
    May 29, 2018
    
    </p>
  </header>
  <section class="post-content"><p>Review: VGGNet은 구조가 간단하며 이해나 변형이 쉬운 장점을 가진다. 하지만 FC로 인해 파라미터의 수가 매우 많다는 단점을 가지며, 이로 인해 필요한 메모리 수가 크고, 학습 시간이 오래 걸린다는 약점을 가진다.</p>

<!--more-->
<h1 id="vggnet-very-deep-convolutional-networks-for-large-scale-image-recognition">VGGNet: Very Deep Convolutional Networks for Large-Scale Image Recognition</h1>
<ul>
  <li>References
    <ul>
      <li>Simonyan, Karen, and Andrew Zisserman. “Very deep convolutional networks for large-scale image recognition.” (2014). <a href="https://arxiv.org/pdf/1409.1556.pdf">[pdf]</a></li>
    </ul>
  </li>
</ul>

<h2 id="abstract">Abstract</h2>
<ul>
  <li>주요 연구 목적은 망의 깊이(depth)가 정확도에 미치는 영향력이다.</li>
  <li>주요 연구 성과는 3x3 convolution filter를 사용한 구조에서 망의 깊이를 증가시켰을 때 보여진 향상된 결과와 그 평가이다. (16~19 레이어)</li>
  <li>ImageNet Challenge 2014에서 localisation 1위, classification 2위 (GoogLeNet이 1위)</li>
</ul>

<h2 id="1-introduction">1. Introduction</h2>
<ul>
  <li>Convolutional networks (ConvNets)가 이미지와 영상 인지에서 큰 성과를 보여줌.
    <ul>
      <li>예시 1) ILSVRC2013에서 ZFNet은 첫번째 convolutional layer에서 AlexNet보다 작은 filter(window) size와 stride 사이즈를 적용하여 성능향상. (Zeiler &amp; Fergus, 2013; Sermanet et al., 2014).</li>
      <li>예시 2) (Sermanet et al., 2014; Howard, 2014)에서 training과 testing에서의 scale 조정, data augmentation 등이 연구됨.</li>
    </ul>
  </li>
  <li>본 연구에서는 3x3 convolution filster를 활용하여 망의 깊이(depth)에 집중함.</li>
  <li>결과적으로, ImageNet 챌린지뿐 아니라 다른 데이터셋에서도 좋은 성과를 보임.</li>
</ul>

<h2 id="2-convnet-configurations">2. ConvNet Configurations</h2>
<p>망 구성에 관한 설명.</p>
<ul>
  <li>깊이에 의한 향상도를 측정하기 위해 ConvNet layer들이 동일하게 설정됨.</li>
</ul>

<h3 id="21-architecture">2.1. Architecture</h3>
<ul>
  <li>training 중에는, 입력 데이터가 224x224 RGB 이미지로 고정됨.</li>
  <li>전처리는, 각 pixel에 RGB의 평균값을 빼준다.</li>
  <li>conv. layers에서 3x3 필터를 사용. stride = 1</li>
  <li>Max-pooling 2x2 filter, stride = 2</li>
  <li>추가적으로 특정 설정에서는 1x1 conv. filter를 적용하여, (ReLU를 통한) 추가적인 non-linearity 확보.</li>
  <li>conv. layers 이후에, 3개의 Fully-Connected(FC) layers를 적용. (각 FC의 출력 채널수: 4096, 4096, 1000)</li>
  <li>마지막에 soft-max layer 적용.</li>
  <li>모든 hidden layers에는 ReLU 적용.</li>
  <li>Local Response Normalisation(LRN) normalisation을 미적용 (Krizhevsky et al., 2012). 적용시, 메모리 소모와 연산 시간 소모 증가를 보임.</li>
</ul>

<h3 id="22-configurations">2.2. Configurations</h3>
<ul>
  <li>A부터 E까지 총 6가지 구성으로 나뉜다. ([Table 1] 참고)
    <ul>
      <li>layers의 수와 1x1 conv. layer의 추가 등에 따라 조금씨 다름.</li>
    </ul>
  </li>
</ul>

<h3 id="23-discussion">2.3. Discussion</h3>
<ul>
  <li>이전의 연구들이 상대적으로 큰 필터를 사용한 것에 비해, 본 연구는 3x3의 매우 작은 필터와 stride 1을 적용함.
    <ul>
      <li>3x3 필터 2개로 5x5 필터의 효과, 3x3 필터 3개로 7x7 필터의 효과를 보며, 오히려 파라미터는 더 적게 사용됨(비용이 작음). (9+9 &lt; 25, 9+9+9 &lt; 49)</li>
    </ul>
  </li>
  <li>1x1 conv. filter를 적용하여, 차원을 유지하며 ReLU를 통한 추가적인 non-linearity 확보.</li>
</ul>

<h2 id="3-classification-framework">3. Classification Framework</h2>
<p>training과 evaluation에 관한 설명.</p>

<h3 id="31-training">3.1. Training</h3>
<ul>
  <li>optimizer에는, mini-batch gradient descent(SGD)와 momentum(모멘텀) 적용.
    <ul>
      <li>batch size = 256, momentum = 0.9</li>
    </ul>
  </li>
  <li>regularisation에는, L2 패널티와 dropout 적용.
    <ul>
      <li>dropout은 0.5로 1st 2nd FC에 적용.</li>
    </ul>
  </li>
  <li>learning rate = <script type="math/tex">10^{-2}</script>, 정확도가 향상되지 않을 경우 학습도가 감소하게 설정.</li>
  <li>Deep net은 학습할 때 vanishing/exploding gradient 문제로 학습이 어려워질 수 있는데, 이것을 먼저 11-layer의 비교적 간단한 구조(A)를 학습시킨 후, 더 깊은 나머지 구조를 학습할 때는 처음 4 layer와 마지막 3개 FC를 구조-A의 학습결과로 초기화 시킨 후 학습을 진행하여 해결하였다.</li>
</ul>

<p><strong>Training image size</strong></p>
<ul>
  <li>data augmentation기법을 적용함.</li>
  <li>예시) AlexNet, 학습 이미지를 256x256 크기로 만든 후, 무작위로 224x224 크기의 이미지로 잘라서 취함.</li>
  <li>training scale로 single-scale training과 multi-scaling training 지원.
    <ul>
      <li>single-scale에서는 256x256 고정과, 256x256과 384x384를 지원하는 두가지 scale 지원.</li>
      <li>multi-scale에서는 min = 256, max = 512로 하여, 256과 512범위에서 무작위로 scale을 정할 수 있게 함. 384로 미리 학습시킨 후 무작위로 선택하며 fine tuning을 함. scale jittering이라고 함.</li>
    </ul>
  </li>
  <li>이후 224x224 크기를 선택하여 취함(AlexNet과 동일).</li>
</ul>

<h3 id="32-testing">3.2. Testing</h3>
<ul>
  <li>test scale을 사용하여, 테스트 이미지를 적당한 크기로 조절함.</li>
  <li>multi-crop 방식(무작위 선택, 코너 및 센터 등의 이미지를 선택하여 좌우반전 적용)의 테스트 이미지 augmentation을 적용. (150장으로 augmentation).</li>
  <li>연산량을 줄이기 위해 OverFeat 구조에서 사용한 <strong>dense evaluation</strong> 개념을 적용. <br />
위를 위해 참고 <a href="https://laonple.blog.me/220749876381">[link]</a></li>
</ul>

<h3 id="33-implementation-details">3.3. Implementation Details</h3>
<ul>
  <li>4개의 NVIDIA Titan Black GPU로 하나의 net 구성을 학습시키는데 2-3주 걸림.</li>
</ul>

<h2 id="4-classification-experiments">4. Classification Experiments</h2>
<p><strong>Dataset</strong></p>
<ul>
  <li>ILSVRC-2012 dataset을 사용.
    <ul>
      <li>1000 class</li>
      <li>sets: training(1.3M images), validation(50k images), testing(100k images with held-out class labels).</li>
      <li>evaluating measures: the top-1 and top-5 error.</li>
    </ul>
  </li>
</ul>

<h3 id="41-single-scale-evaluation">4.1. Single Scale Evaluation</h3>
<ul>
  <li>[Table 3] 참고</li>
  <li>망이 깊을수록 결과가 좋아지고, 학습에 scale jittering을 적용한 경우에 결과가 더 좋았다.</li>
  <li>B구조에 3x3 conv. layer 2개를 곂쳐서 사용한 경우와 5x5 conv. layer를 1개 사용하는 모델을 만들어 비교함.
    <ul>
      <li>3x3 conv. layer 2개인 모델이 결과가 더 좋았다.</li>
      <li>망을 깊게 만들고, 파라미터의 크기를 줄이고, 뉴런에 있는 non-linearity 활성함수를 통해 feature 추출 특성이 좋아졌음을 반증함.</li>
    </ul>
  </li>
</ul>

<h3 id="42-multi-scale-evaluation">4.2. Multi-Scale Evaluation</h3>
<ul>
  <li>[Table 4] 참고</li>
  <li>multi-scale test에서 train-scale(S)이 고정된 경우에, {S-32, S, S+32}로 test-scale을 변화시키며 테스트 진행. (train과 test의 scale 차이가 크면 오히려 결과가 좋지 못해서 이와 같이 설정.)</li>
  <li>학습에 scale jittering을 적용한 경우 출력 크기를 [256, 384,512]로 test 이미지 크기를 정함. 결과는 더 미적용보다 좋았음.</li>
  <li>single scale보다 multi scale이 결과가 더 좋았음.</li>
</ul>

<h3 id="43-multi-crop-evaluation">4.3. Multi-Crop Evaluation</h3>
<ul>
  <li>[Table 5] 참고</li>
  <li>multi-crop과 dense evaluation은 각각 적용했을 때와 같이 적용했을 때로 나누어 진행함.</li>
  <li>함께 진행한 경우, 상보적인 특성을 갖고 있어 성능이 개선되었다고 함.</li>
</ul>

<h3 id="44-convnet-fusion">4.4. ConvNet Fusion</h3>
<ul>
  <li>구조 D와 E에 multi-scale과 multi-crop evaluation, dense evaluation을 적용한 앙상블 구조가 가장 좋은 성과를 보임.</li>
</ul>

<h3 id="45-comparision-with-the-state-of-the-art">4.5. Comparision with the State-of-the-Art</h3>
<ul>
  <li>VGGNet의 위 2개 모델 앙상블이 top-5 val. error와 top-5 test error 6.8%.</li>
  <li>GoogLeNet의 7개 모델 앙상블이 top-5 val. error와 top-5 test error 6.7%.</li>
</ul>

<h2 id="5-conclusion">5. Conclusion</h2>
<ul>
  <li>망의 깊이가 분류의 정확도에 유익한 영향을 미치며, 챌린지를 통해 기존의 ConvNet 구조에서 망의 깊이 증가를 통해 좋은 성능을 보여줄 수 있음을 알 수 있었음.</li>
</ul>
</section>
  
  <!-- Social media shares -->
  <footer>
<div class="share-buttons">
<ul class="share-buttons">
	
	<li>
		<!-- <a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/2018/05/29/VeryDeepConvolutionalNetworksforLargeScaleImageRecognition_VGGNet.html&quote=VGGNet, "Very Deep Convolutional Networks for Large-Scale Image Recognition" (2014)%20%7C%20DaMacho" target="_blank" title="Share on Facebook"> -->
		<!-- <a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/2018/05/29/VeryDeepConvolutionalNetworksforLargeScaleImageRecognition_VGGNet.html" onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;"> -->
		<a href="https://www.facebook.com/sharer/sharer.php?u=https://damacho.github.io/2018/05/29/VeryDeepConvolutionalNetworksforLargeScaleImageRecognition_VGGNet.html" onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
			<i class="fa fa-facebook-square fa-2x" aria-hidden="true"></i>
			<span class="sr-only">Share on Facebook</span>
		</a>
	</li>
	

	
	<li>
		<!-- <a href="https://twitter.com/intent/tweet?source=http://localhost:4000/2018/05/29/VeryDeepConvolutionalNetworksforLargeScaleImageRecognition_VGGNet.html&text=VGGNet, "Very Deep Convolutional Networks for Large-Scale Image Recognition" (2014)%20%7C%20DaMacho:%20http://localhost:4000/2018/05/29/VeryDeepConvolutionalNetworksforLargeScaleImageRecognition_VGGNet.html" target="_blank" title="Tweet"> -->
		<a href="https://twitter.com/intent/tweet?source=https://damacho.github.io/2018/05/29/VeryDeepConvolutionalNetworksforLargeScaleImageRecognition_VGGNet.html&text=VGGNet, "Very Deep Convolutional Networks for Large-Scale Image Recognition" (2014)%20%7C%20DaMacho:%20https://damacho.github.io/2018/05/29/VeryDeepConvolutionalNetworksforLargeScaleImageRecognition_VGGNet.html" target="_blank" title="Tweet">
			<i class="fa fa-twitter-square fa-2x" aria-hidden="true"></i>
			<span class="sr-only">Tweet</span>
		</a>
	</li>
	

	

	

	

	

	
	<li>
		<!-- <a href="http://www.reddit.com/submit?url=http://localhost:4000/2018/05/29/VeryDeepConvolutionalNetworksforLargeScaleImageRecognition_VGGNet.html&title=VGGNet, "Very Deep Convolutional Networks for Large-Scale Image Recognition" (2014)%20%7C%20DaMacho" target="_blank" title="Share on Reddit"> -->
		<a href="http://www.reddit.com/submit?url=https://damacho.github.io/2018/05/29/VeryDeepConvolutionalNetworksforLargeScaleImageRecognition_VGGNet.html&title=VGGNet, "Very Deep Convolutional Networks for Large-Scale Image Recognition" (2014)%20%7C%20DaMacho" target="_blank" title="Share on Reddit">
			<i class="fa fa-reddit-square fa-2x" aria-hidden="true"></i>
			<span class="sr-only">Share on Reddit</span>
		</a>
	</li>
	

	

	

	
</ul>
</div>
</footer>

   
   <!-- Tag list -->
  
  


<footer>
  <div class="tag-list">
    
      <div class="meta">Tags</div>
    

    
    <a class="button" href="/tags#Paper_Review">
      <p><i class="fa fa-tag fa-fw"></i> Paper_Review</p>
    </a>
    
  </div>
</footer>

    
</article>

<!-- Disqus -->


<!-- Post navigation -->

  <div id="post-nav">
  
  <div id="previous-post" class="post-nav-post">
      <p>Previous post</p>
      <a href="/2018/05/22/next_step.html">
        블로그 건설 중, 다음으로 할 것
      </a>
  </div>
  
  
  <div id="next-post" class="post-nav-post">
      <p>Next post</p>
      <a href="/2018/06/05/ImprovingNeuralNetowrksbyPreventingCoadaptationofFeatureDetectors.html">
        Dropout, "Improving neural networks by preventing co-adaptation of feature detectors" (2012)
      </a>
  </div>
  
</div>

    </div>
    
<footer class="site-footer">
    <p class="text">Powered by <a href="https://jekyllrb.com/">Jekyll</a> with <a href="https://github.com/sylhare/Type-on-Strap">Type on Strap</a>
</p>
            <div class="footer-icons">
                <ul>
                <!-- Social icons from Font Awesome, if enabled -->
                


<li>
	<a href="mailto:po4865@gmail.com" title="Email">
		<span class="fa-stack fa-lg">
            <i class="fa fa-circle fa-stack-2x"></i>
            <i class="fa fa-envelope fa-stack-1x fa-inverse"></i>
        </span>
	</a>
</li>













<li>
	<a href="https://github.com/DaMacho" title="Follow on GitHub">
		<span class="fa-stack fa-lg">
            <i class="fa fa-circle fa-stack-2x"></i>
            <i class="fa fa-github fa-stack-1x fa-inverse"></i>
        </span>
	</a>
</li>
































                </ul>
            </div>
</footer>




  </body>
</html>
